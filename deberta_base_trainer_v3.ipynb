{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "deberta_base_trainer_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp-6-Wqrfi3i",
        "outputId": "971b15a6-cb1b-42c3-af35-755d659852a4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-07-24T17:01:03.162824Z",
          "iopub.execute_input": "2021-07-24T17:01:03.163202Z",
          "iopub.status.idle": "2021-07-24T17:01:10.032727Z",
          "shell.execute_reply.started": "2021-07-24T17:01:03.163096Z",
          "shell.execute_reply": "2021-07-24T17:01:10.031891Z"
        },
        "trusted": true,
        "id": "AKkdo8JJfc-R"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel, AutoConfig\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import os\n",
        "import random\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import gc\n",
        "gc.enable()\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "#import nltk\n",
        "#from nltk import word_tokenize"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:01:12.693554Z",
          "iopub.execute_input": "2021-07-24T17:01:12.693858Z",
          "iopub.status.idle": "2021-07-24T17:01:12.697875Z",
          "shell.execute_reply.started": "2021-07-24T17:01:12.693830Z",
          "shell.execute_reply": "2021-07-24T17:01:12.696784Z"
        },
        "trusted": true,
        "id": "gXQe3g1Xfc-T"
      },
      "source": [
        "config = {\n",
        "    'train_batch_size': 16,\n",
        "    'valid_batch_size': 32,\n",
        "    'max_len': 314,\n",
        "    'nfolds': 5,\n",
        "    'seed': 42,\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:01:13.593791Z",
          "iopub.execute_input": "2021-07-24T17:01:13.594116Z",
          "iopub.status.idle": "2021-07-24T17:01:13.648592Z",
          "shell.execute_reply.started": "2021-07-24T17:01:13.594085Z",
          "shell.execute_reply": "2021-07-24T17:01:13.647398Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikm8a0aAfc-U",
        "outputId": "260a55a7-801b-4bc8-e540-3f9cc3802353"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'{device} is used')\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONASSEED'] = str(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.detarministic = True \n",
        "    torch.backends.cudnn.benchmark = True \n",
        "\n",
        "seed_everything(seed=42)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:01:14.731572Z",
          "iopub.execute_input": "2021-07-24T17:01:14.731879Z",
          "iopub.status.idle": "2021-07-24T17:01:14.837371Z",
          "shell.execute_reply.started": "2021-07-24T17:01:14.731851Z",
          "shell.execute_reply": "2021-07-24T17:01:14.836534Z"
        },
        "trusted": true,
        "id": "KZTqdRVffc-V"
      },
      "source": [
        "train_data = pd.read_csv(\"/content/train.csv\")\n",
        "#test_data = pd.read_csv(\"/content/test.csv\")\n",
        "#sample_data = pd.read_csv(\"/content/sample_submission.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:01:15.566440Z",
          "iopub.execute_input": "2021-07-24T17:01:15.566860Z",
          "iopub.status.idle": "2021-07-24T17:01:15.633406Z",
          "shell.execute_reply.started": "2021-07-24T17:01:15.566820Z",
          "shell.execute_reply": "2021-07-24T17:01:15.632495Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1puEltVmfc-V",
        "outputId": "37143515-b5a3-476d-c49d-5c5576d9776a"
      },
      "source": [
        "idf = [len(x.split()) for x in train_data.excerpt]\n",
        "print (max(idf), min(idf))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "205 135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:01:16.336097Z",
          "iopub.execute_input": "2021-07-24T17:01:16.336461Z",
          "iopub.status.idle": "2021-07-24T17:01:16.357407Z",
          "shell.execute_reply.started": "2021-07-24T17:01:16.336431Z",
          "shell.execute_reply": "2021-07-24T17:01:16.356593Z"
        },
        "trusted": true,
        "id": "DFVQmq4tfc-W"
      },
      "source": [
        "# k-fold\n",
        "num_bins = int(np.floor(1 + np.log2(len(train_data))))\n",
        "train_data.loc[:, 'bins'] = pd.cut(train_data['target'], bins=num_bins, labels=False)\n",
        "\n",
        "train_data['kfold'] = -1\n",
        "kfold = StratifiedKFold(n_splits=config['nfolds'],\n",
        "                        shuffle=True,\n",
        "                        random_state=config['seed'])\n",
        "for k, (train_idx, valid_idx) in enumerate(kfold.split(X=train_data, y=train_data.bins)):\n",
        "    train_data.loc[valid_idx, 'kfold'] = k\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:01:17.384001Z",
          "iopub.execute_input": "2021-07-24T17:01:17.384370Z",
          "iopub.status.idle": "2021-07-24T17:01:17.391128Z",
          "shell.execute_reply.started": "2021-07-24T17:01:17.384336Z",
          "shell.execute_reply": "2021-07-24T17:01:17.390027Z"
        },
        "trusted": true,
        "id": "7BkEEkoxfc-W"
      },
      "source": [
        "class clrp(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:01:19.040803Z",
          "iopub.execute_input": "2021-07-24T17:01:19.041122Z",
          "iopub.status.idle": "2021-07-24T17:01:19.265663Z",
          "shell.execute_reply.started": "2021-07-24T17:01:19.041092Z",
          "shell.execute_reply": "2021-07-24T17:01:19.264682Z"
        },
        "trusted": true,
        "id": "ILuBW3vafc-W"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjmUt2fZ_wHK",
        "outputId": "8391a7f3-cb7c-474d-bca1-0aa3b9449aeb"
      },
      "source": [
        "def weight(dim_in, dim_out, factorize_k = None):\n",
        "    if factorize_k is None:\n",
        "        return nn.Linear(dim_in, dim_out, bias = False)\n",
        "\n",
        "    assert factorize_k < dim_in and factorize_k < dim_out, 'k must be of relative lower rank'\n",
        "\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(dim_in, factorize_k, bias = False),\n",
        "        nn.Linear(factorize_k, dim_out, bias = False)\n",
        "    )\n",
        "\n",
        "class Mogrifier(nn.Module):\n",
        "    def __init__(self, dim, iters = 5, factorize_k = None):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.iters = iters\n",
        "\n",
        "        self.Q = weight(dim, dim, factorize_k)\n",
        "        self.R = weight(dim, dim, factorize_k) if iters > 1 else None\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        shape = x.shape\n",
        "        *_, dim = shape\n",
        "        assert dim == self.dim, f'mogrifier accepts a dimension of {self.dim}'\n",
        "\n",
        "        x, h = map(lambda t: t.reshape(-1, dim), (x, h))\n",
        "\n",
        "        for ind in range(self.iters):\n",
        "            if (ind % 2) == 0:\n",
        "                x = 2 * self.Q(h).sigmoid() * x\n",
        "            else:\n",
        "                h = 2 * self.R(x).sigmoid() * h\n",
        "\n",
        "        x, h = map(lambda t: t.reshape(*shape), (x, h))\n",
        "        return x, h\n",
        "class CLRPMogLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        config = AutoConfig.from_pretrained(\"microsoft/deberta-base\")\n",
        "        config.update({\"output_hidden_states\":True, \n",
        "                       \"hidden_dropout_prob\": 0.0,\n",
        "                       \"layer_norm_eps\": 1e-7})                       \n",
        "        \n",
        "        self.transformers = AutoModel.from_pretrained(\"microsoft/deberta-base\", config=config)  \n",
        "\n",
        "        self.mog_lstm_1 = Mogrifier(\n",
        "                          dim = 768,\n",
        "                          iters = 5,          # number of iterations, defaults to 5 as paper recommended for LSTM\n",
        "                          factorize_k = 16    # factorize weight matrices into (dim x k) and (k x dim), if specified\n",
        "                      )\n",
        "        self.mog_lstm_2 = Mogrifier(\n",
        "                          dim = 768,\n",
        "                          iters = 5,          # number of iterations, defaults to 5 as paper recommended for LSTM\n",
        "                          factorize_k = 8    # factorize weight matrices into (dim x k) and (k x dim), if specified\n",
        "                      )\n",
        "        \n",
        "\n",
        "        self.relu = nn.GELU()\n",
        "            \n",
        "        self.attention = nn.Sequential(            \n",
        "            nn.Linear(768, 512),            \n",
        "            nn.Tanh(),                       \n",
        "            nn.Linear(512, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )        \n",
        "\n",
        "        self.regressor = nn.Sequential(                        \n",
        "            nn.Linear(768, 1)                        \n",
        "        )\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        transformers_outputs = self.transformers(input_ids=input_ids,\n",
        "                                      attention_mask=attention_mask,\n",
        "                                     token_type_ids= token_type_ids)        \n",
        "\n",
        "        # There are a total of 13 layers of hidden states.\n",
        "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
        "        # We take the hidden states from the last Roberta layer.\n",
        "        last_layer_hidden_states = transformers_outputs.last_hidden_state\n",
        "\n",
        "        #mog lstm\n",
        "        h = torch.zeros(last_layer_hidden_states.shape[0], last_layer_hidden_states.shape[1], last_layer_hidden_states.shape[2]).to(device)\n",
        "        mog_1, z = self.mog_lstm_1(last_layer_hidden_states, h)\n",
        "        mog_1 = self.relu(mog_1)\n",
        "\n",
        "        h2 = torch.zeros(last_layer_hidden_states.shape[0], last_layer_hidden_states.shape[1], last_layer_hidden_states.shape[2]).to(device)\n",
        "        mog_2, z2 = self.mog_lstm_2(mog_1, h2)\n",
        "        mog_2 = self.relu(mog_2)\n",
        "\n",
        "        # The number of cells is MAX_LEN.\n",
        "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
        "        # In order to condense hidden states of all cells to a context vector,\n",
        "        # we compute a weighted average of the hidden states of all cells.\n",
        "        # We compute the weight of each cell, using the attention neural network.\n",
        "        weights = self.attention(mog_2)\n",
        "                \n",
        "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
        "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
        "        # Now we compute context_vector as the weighted average.\n",
        "        # context_vector.shape is BATCH_SIZE x 768\n",
        "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
        "        \n",
        "        # Now we reduce the context vector to the prediction score.\n",
        "        return self.regressor(context_vector)\n",
        "model_lit = CLRPMogLSTM()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'config', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight']\n",
            "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T16:28:55.592624Z",
          "iopub.status.idle": "2021-07-24T16:28:55.593206Z"
        },
        "trusted": true,
        "id": "7E6Lv8cdfc-Y"
      },
      "source": [
        "#model_auto = AutoModelForSequenceClassification.from_pretrained(\"../input/huggingface-deberta-variants/deberta-base/deberta-base\", num_labels=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T16:28:55.594825Z",
          "iopub.status.idle": "2021-07-24T16:28:55.595495Z"
        },
        "trusted": true,
        "id": "dcGuJsbofc-Z"
      },
      "source": [
        "#for param in model_lit.base_model.parameters():\n",
        "    #param.requires_grad = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T16:28:55.596973Z",
          "iopub.status.idle": "2021-07-24T16:28:55.597694Z"
        },
        "trusted": true,
        "id": "sBKhYaPUfc-Z"
      },
      "source": [
        "#for param in model.roberta.parameters():\n",
        "    #param.requires_grad = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:01:42.331767Z",
          "iopub.execute_input": "2021-07-24T17:01:42.332266Z",
          "iopub.status.idle": "2021-07-24T17:01:44.171144Z",
          "shell.execute_reply.started": "2021-07-24T17:01:42.332215Z",
          "shell.execute_reply": "2021-07-24T17:01:44.170256Z"
        },
        "trusted": true,
        "id": "Wj5D7HIefc-Z"
      },
      "source": [
        "p_fold = 0\n",
        "p_train = train_data.query(f'kfold != {p_fold}').reset_index(drop=True)\n",
        "p_valid = train_data.query(f'kfold == {p_fold}').reset_index(drop=True)\n",
        "tokenizer_train = tokenizer.batch_encode_plus(p_train.excerpt.replace(\"\\n\", \" \").to_list(),\n",
        "                                          add_special_tokens=True,\n",
        "                                          max_length=250,\n",
        "                                          pad_to_max_length=True,\n",
        "                                          truncation=True,\n",
        "                                          return_attention_mask=True)\n",
        "tokenizer_val = tokenizer.batch_encode_plus(p_valid.excerpt.replace(\"\\n\", \" \").to_list(),\n",
        "                                          add_special_tokens=True,\n",
        "                                          max_length=250,\n",
        "                                          pad_to_max_length=True,\n",
        "                                          truncation=True,\n",
        "                                          return_attention_mask=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:01:44.174850Z",
          "iopub.execute_input": "2021-07-24T17:01:44.175137Z",
          "iopub.status.idle": "2021-07-24T17:01:44.182683Z",
          "shell.execute_reply.started": "2021-07-24T17:01:44.175108Z",
          "shell.execute_reply": "2021-07-24T17:01:44.181793Z"
        },
        "trusted": true,
        "id": "-NRW7uXmfc-a"
      },
      "source": [
        "train_dataset = clrp(tokenizer_train, p_train.target.to_list())\n",
        "val_dataset = clrp(tokenizer_val, p_valid.target.to_list())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:02:08.350123Z",
          "iopub.execute_input": "2021-07-24T17:02:08.350489Z",
          "iopub.status.idle": "2021-07-24T17:02:08.358054Z",
          "shell.execute_reply.started": "2021-07-24T17:02:08.350459Z",
          "shell.execute_reply": "2021-07-24T17:02:08.357123Z"
        },
        "trusted": true,
        "id": "7Oqay-wafc-a"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=1,\n",
        "    do_train=True,\n",
        "    do_eval=False,\n",
        "    do_predict=True,\n",
        "    num_train_epochs=5,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=250,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    #learning_rate=5e-6,\n",
        "    seed=99,\n",
        "    lr_scheduler_type=\"cosine\"\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:02:10.532968Z",
          "iopub.execute_input": "2021-07-24T17:02:10.533291Z",
          "iopub.status.idle": "2021-07-24T17:02:10.539174Z",
          "shell.execute_reply.started": "2021-07-24T17:02:10.533261Z",
          "shell.execute_reply": "2021-07-24T17:02:10.538201Z"
        },
        "trusted": true,
        "id": "7dgMyPgZfc-a"
      },
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
        "        return loss\n",
        "rmse_loss = RMSELoss()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:02:10.888813Z",
          "iopub.execute_input": "2021-07-24T17:02:10.889128Z",
          "iopub.status.idle": "2021-07-24T17:02:10.894799Z",
          "shell.execute_reply.started": "2021-07-24T17:02:10.889098Z",
          "shell.execute_reply": "2021-07-24T17:02:10.893484Z"
        },
        "trusted": true,
        "id": "4i4qo28sfc-a"
      },
      "source": [
        "class RMSE_Trainner(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs\n",
        "        #loss = torch.sqrt(nn.functional.mse_loss(logits,labels.unsqueeze(1)))\n",
        "        loss = rmse_loss(logits, labels.unsqueeze(1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:02:12.862053Z",
          "iopub.execute_input": "2021-07-24T17:02:12.862447Z",
          "iopub.status.idle": "2021-07-24T17:02:13.232787Z",
          "shell.execute_reply.started": "2021-07-24T17:02:12.862409Z",
          "shell.execute_reply": "2021-07-24T17:02:13.231960Z"
        },
        "trusted": true,
        "id": "4-kuqoTNfc-b"
      },
      "source": [
        "trainer = RMSE_Trainner(\n",
        "    model=model_lit,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset      # evaluation dataset\n",
        "    #compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:02:14.571015Z",
          "iopub.execute_input": "2021-07-24T17:02:14.571353Z",
          "iopub.status.idle": "2021-07-24T17:05:30.032258Z",
          "shell.execute_reply.started": "2021-07-24T17:02:14.571324Z",
          "shell.execute_reply": "2021-07-24T17:05:30.031445Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "0XTle8GNfc-b",
        "outputId": "9654e0d1-c3f1-415f-e1f9-af63bd78032e"
      },
      "source": [
        "gc.collect()\n",
        "trainer.train()\n",
        "del trainer"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 2267\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 710\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='710' max='710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [710/710 25:10, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.654600</td>\n",
              "      <td>0.762035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.474600</td>\n",
              "      <td>0.574683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.382800</td>\n",
              "      <td>0.518455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.281500</td>\n",
              "      <td>0.485008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.180000</td>\n",
              "      <td>0.479088</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 567\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-142\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Deleting older checkpoint [results/checkpoint-568] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 567\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-284\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Deleting older checkpoint [results/checkpoint-710] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 567\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-426\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Deleting older checkpoint [results/checkpoint-142] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 567\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-568\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Deleting older checkpoint [results/checkpoint-284] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 567\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-710\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Deleting older checkpoint [results/checkpoint-426] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-710 (score: 0.4790883958339691).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSrxragwV8hd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNxnYkseU2Sm"
      },
      "source": [
        "class clrp_test(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        #item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "tokenizer_test = tokenizer.batch_encode_plus(test_data.excerpt.to_list(),\n",
        "                                          max_length=205,\n",
        "                                          pad_to_max_length=True,\n",
        "                                          truncation=True)\n",
        "test_datasets = clrp_test(tokenizer_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G1iDOwyU8Bn"
      },
      "source": [
        "def predict(model_path, data):\n",
        "    model_lit_infer = LitModel()\n",
        "    model_lit_infer.load_state_dict(torch.load(model_path)) \n",
        "    model_lit_infer.to(device)\n",
        "    result = []\n",
        "    trainer_inter_arg  = TrainingArguments(\n",
        "    output_dir='./results/pred',          # output directory\n",
        "    do_train=False,\n",
        "    do_eval=False,\n",
        "    do_predict=True\n",
        "    )\n",
        "    trainer_infer = Trainer(\n",
        "        model = model_lit_infer,\n",
        "        args=trainer_inter_arg\n",
        "    )\n",
        "    out_pred, _, __ = trainer_infer.predict(data)\n",
        "    del trainer_infer\n",
        "    return out_pred.squeeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:07:03.410565Z",
          "iopub.execute_input": "2021-07-24T17:07:03.410888Z",
          "iopub.status.idle": "2021-07-24T17:07:03.416484Z",
          "shell.execute_reply.started": "2021-07-24T17:07:03.410860Z",
          "shell.execute_reply": "2021-07-24T17:07:03.415621Z"
        },
        "trusted": true,
        "id": "Oph7jlwUfc-c",
        "outputId": "083fd941-6da1-488c-d6b0-ddc23fdba56f"
      },
      "source": [
        "len(val_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:07:05.865481Z",
          "iopub.execute_input": "2021-07-24T17:07:05.865800Z",
          "iopub.status.idle": "2021-07-24T17:07:11.964471Z",
          "shell.execute_reply.started": "2021-07-24T17:07:05.865770Z",
          "shell.execute_reply": "2021-07-24T17:07:11.963583Z"
        },
        "trusted": true,
        "id": "W1jsFPmIfc-c"
      },
      "source": [
        "out_pred, _, __ = trainer.predict(val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:07:22.158092Z",
          "iopub.execute_input": "2021-07-24T17:07:22.158536Z",
          "iopub.status.idle": "2021-07-24T17:07:22.164296Z",
          "shell.execute_reply.started": "2021-07-24T17:07:22.158502Z",
          "shell.execute_reply": "2021-07-24T17:07:22.163364Z"
        },
        "trusted": true,
        "id": "U-djn4Ltfc-c",
        "outputId": "cae81d61-1394-4535-beaf-c7c340da658d"
      },
      "source": [
        "len(out_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "531"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T17:06:13.853284Z",
          "iopub.execute_input": "2021-07-24T17:06:13.853654Z",
          "iopub.status.idle": "2021-07-24T17:06:13.887600Z",
          "shell.execute_reply.started": "2021-07-24T17:06:13.853618Z",
          "shell.execute_reply": "2021-07-24T17:06:13.885601Z"
        },
        "trusted": true,
        "id": "DIv-zLb8fc-c",
        "outputId": "1ba19eff-6a2d-4ced-b7bb-280c8e6e0533"
      },
      "source": [
        "sample_data.target = (out_pred)\n",
        "sample_data.to_csv('submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length of values (6) does not match length of index (7)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-c47b40c3aef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                     \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5493\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m                     \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3240\u001b[0m         \"\"\"\n\u001b[1;32m   3241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3242\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3243\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3898\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3899\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         raise ValueError(\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (6) does not match length of index (7)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-24T16:54:11.450859Z",
          "iopub.status.idle": "2021-07-24T16:54:11.451580Z"
        },
        "trusted": true,
        "id": "onfEnf4zfc-d"
      },
      "source": [
        "sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rjxSPacUfc-d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN9dqpgmfc-d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}